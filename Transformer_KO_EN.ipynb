{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module Import & Data Preparation"
      ],
      "metadata": {
        "id": "f29WtLFlKzdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important Installations"
      ],
      "metadata": {
        "id": "ofN-FJdWqw-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tWzsbj2fmuk"
      },
      "outputs": [],
      "source": [
        "!pip install torchtext==0.12.0\n",
        "!pip install konlpy\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"
      ],
      "metadata": {
        "id": "5qBJFkhVQ_Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "3lR6B-6Zrxu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5STNCN07r7Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/24Fall_NLP')\n",
        "# os.chdir('/content/drive/MyDrive/YAI/24Fall_NLP')"
      ],
      "metadata": {
        "id": "N9hq8CQWsCQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Mandatory Modules"
      ],
      "metadata": {
        "id": "z4a-xfaatw3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext.transforms as transforms\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from konlpy.tag import Okt\n",
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "metadata": {
        "id": "AJYHGA942gbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "HVMyjN-Xqy8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "data = glob('./한영번역_sample/*.xlsx')"
      ],
      "metadata": {
        "id": "F3wFGQnhqp_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = './한영번역_sample/'"
      ],
      "metadata": {
        "id": "O4dxHn6X7CC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "J2qAHLEEt_I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = [os.path.basename(file) for file in data]\n",
        "\n",
        "df = pd.DataFrame(columns=['kr', 'en'])\n",
        "\n",
        "for datum in data:\n",
        "    temp = pd.read_excel(datum)\n",
        "    exs_columns_en = [col for col in temp.columns if col in ['영어검수', '검수', 'Review', 'REVIEW']]\n",
        "    exs_columns_kr = [col for col in temp.columns if col in ['원문','한국어']]\n",
        "    if exs_columns_en:\n",
        "        temp = temp.rename(columns={col:'en' for col in exs_columns_en})\n",
        "    if exs_columns_kr:\n",
        "        temp = temp.rename(columns={col:'kr' for col in exs_columns_kr})\n",
        "\n",
        "    df = pd.concat([df, temp[['kr', 'en']]])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Wrn9mcvpufIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QCcRFbpf1_sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Preparation"
      ],
      "metadata": {
        "id": "hqi32Xzu6C69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "df_shuffled = df.sample(frac=1).reset_index(drop=True) # 전체 문장들을 무작위로 섞은 뒤 인덱스를 리셋해준다\n",
        "df = df_shuffled[:30000] # 그 중 30,000개 문장만 가져와 사용\n",
        "\n",
        "for i, (train_idx, val_idx) in enumerate(kf.split(df['kr'])):\n",
        "    train = df.iloc[train_idx]\n",
        "    val = df.iloc[val_idx]\n",
        "\n",
        "print('train_size: ', len(train))\n",
        "print('val_size: ', len(val))\n",
        "\n",
        "train.to_csv(os.path.join(data_path, 'train.csv'), index=False)\n",
        "val.to_csv(os.path.join(data_path, 'val.csv'), index=False)"
      ],
      "metadata": {
        "id": "EOm1mBLu6NzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 어휘 생성\n",
        "def yield_tokens(data_iter, tokenizer):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# 한국어와 영어 토크나이저 정의\n",
        "tokenizer_kr = Okt()\n",
        "tokenizer_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize_kor(text):\n",
        "    return tokenizer_kr.morphs(text)\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [token.text for token in tokenizer_en(text)]"
      ],
      "metadata": {
        "id": "GwliQTb1I8c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Sentence Check"
      ],
      "metadata": {
        "id": "DhXHQVmr2FeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋에서 샘플 문장 확인\n",
        "sample_kr_sentence = train_df['kr'].iloc[0]  # 첫 번째 샘플 문장 (한국어)\n",
        "sample_en_sentence = train_df['en'].iloc[0]  # 첫 번째 샘플 문장 (영어)\n",
        "\n",
        "# 토큰화된 결과 출력\n",
        "print(\"Korean Sentence:\", sample_kr_sentence)\n",
        "print(\"Tokenized Korean:\", list(yield_tokens([sample_kr_sentence], tokenize_kor)))\n",
        "\n",
        "print(\"English Sentence:\", sample_en_sentence)\n",
        "print(\"Tokenized English:\", list(yield_tokens([sample_en_sentence], tokenize_en)))"
      ],
      "metadata": {
        "id": "pkQhJ6XMolgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(f'{data_path}train.csv')\n",
        "valid_df = pd.read_csv(f'{data_path}val.csv')\n",
        "\n",
        "# 어휘 구축\n",
        "SRC_vocab = build_vocab_from_iterator(yield_tokens(train_df['kr'], tokenize_kor), min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
        "SRC_vocab.set_default_index(SRC_vocab['<unk>'])\n",
        "\n",
        "TRG_vocab = build_vocab_from_iterator(yield_tokens(train_df['en'], tokenize_en), min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
        "TRG_vocab.set_default_index(TRG_vocab['<unk>'])\n",
        "\n",
        "print(f\"len(SRC_vocab): {len(SRC_vocab)}\")\n",
        "print(f\"len(TRG_vocab): {len(TRG_vocab)}\")\n",
        "\n",
        "# Transforms 정의\n",
        "SRC_transform = transforms.Sequential(\n",
        "    transforms.VocabTransform(SRC_vocab),\n",
        "    transforms.AddToken(token=SRC_vocab['<sos>'], begin=True),\n",
        "    transforms.AddToken(token=SRC_vocab['<eos>'], begin=False)\n",
        ")\n",
        "\n",
        "TRG_transform = transforms.Sequential(\n",
        "    transforms.VocabTransform(TRG_vocab),\n",
        "    transforms.AddToken(token=TRG_vocab['<sos>'], begin=True),\n",
        "    transforms.AddToken(token=TRG_vocab['<eos>'], begin=False)\n",
        ")"
      ],
      "metadata": {
        "id": "zeb1H9oIDSj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV 파일을 처리하여 텐서로 변환하는 Dataset 클래스\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, path, src_transform=None, trg_transform=None):\n",
        "        self.data = pd.read_csv(path)\n",
        "        self.src_transform = src_transform\n",
        "        self.trg_transform = trg_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_text = self.data.iloc[idx]['kr']\n",
        "        trg_text = self.data.iloc[idx]['en']\n",
        "\n",
        "        # 토큰화 적용\n",
        "        src_tokenized = tokenize_kor(src_text)\n",
        "        trg_tokenized = tokenize_en(trg_text)\n",
        "\n",
        "        # 변환 적용 (리스트로 감싸서 transform 적용)\n",
        "        if self.src_transform:\n",
        "            src_text = self.src_transform([src_tokenized])  # 리스트로 감싸서 transform 적용\n",
        "        if self.trg_transform:\n",
        "            trg_text = self.trg_transform([trg_tokenized])  # 리스트로 감싸서 transform 적용\n",
        "\n",
        "        return torch.tensor(src_text[0]), torch.tensor(trg_text[0])  # 텐서로 변환"
      ],
      "metadata": {
        "id": "WifGkw2uzZBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        src_batch.append(src_sample)\n",
        "        trg_batch.append(trg_sample)\n",
        "\n",
        "    # 텐서로 변환하고 패딩 처리\n",
        "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=SRC_vocab['<pad>'], batch_first=True)\n",
        "    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=TRG_vocab['<pad>'], batch_first=True)\n",
        "\n",
        "    return src_batch, trg_batch"
      ],
      "metadata": {
        "id": "0epjeOscJETr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 설정\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Dataset 생성\n",
        "train_data = TranslationDataset(train_csv, src_transform=SRC_transform, trg_transform=TRG_transform)\n",
        "valid_data = TranslationDataset(valid_csv, src_transform=SRC_transform, trg_transform=TRG_transform)\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Batch shape 확인\n",
        "for src, trg in train_loader:\n",
        "    print(f\"Source batch shape: {src.shape}\")\n",
        "    print(f\"Target batch shape: {trg.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "B-7Nau8TJGB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Dataset, DataLoader"
      ],
      "metadata": {
        "id": "xrym5a1oQVG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 생성\n",
        "train_data = TranslationDataset(train_csv, src_transform=SRC_transform, trg_transform=TRG_transform)\n",
        "valid_data = TranslationDataset(valid_csv, src_transform=SRC_transform, trg_transform=TRG_transform)\n",
        "\n",
        "# DataLoader 설정\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        src_batch.append(src_sample)\n",
        "        trg_batch.append(trg_sample)\n",
        "\n",
        "    # 텐서로 변환하고 패딩 처리\n",
        "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=SRC_vocab['<pad>'], batch_first=True)\n",
        "    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=TRG_vocab['<pad>'], batch_first=True)\n",
        "\n",
        "    return src_batch, trg_batch\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# DataLoader에서 배치를 받아오는 예시\n",
        "for src, trg in train_loader:\n",
        "    print(f\"Source batch shape: {src.shape}\")\n",
        "    print(f\"Target batch shape: {trg.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "otD7a_7XDOkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper Parameters"
      ],
      "metadata": {
        "id": "C4ZG5HqhQHCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args(\"\")\n",
        "\n",
        "# ====== Random Seed Initialization ====== #\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# ====== Padding Index Setting ====== #\n",
        "# indices of <pad> token\n",
        "SRC_PAD_IDX = SRC_vocab['<pad>']\n",
        "TRG_PAD_IDX = TRG_vocab['<pad>']\n",
        "\n",
        "# ====== Model ====== #\n",
        "args.input_dim = len(SRC_vocab)\n",
        "args.output_dim = len(TRG_vocab)\n",
        "\n",
        "args.hidden_dim = 256 # 512 in the original paper\n",
        "\n",
        "args.max_len = 200 # >= sentence max length\n",
        "\n",
        "args.enc_layers = 3 # 6 in the original paper\n",
        "args.dec_layers = 3\n",
        "\n",
        "args.enc_heads = 8\n",
        "args.dec_heads = 8\n",
        "\n",
        "args.enc_pf_dim = 1024 # 2048 in the original paper\n",
        "args.dec_pf_dim = 1024\n",
        "\n",
        "args.enc_dropout = 0.1\n",
        "args.dec_dropout = 0.1\n",
        "\n",
        "# ====== Optimization ====== #\n",
        "args.lr = 0.0005\n",
        "args.warmup_steps = 4000\n",
        "\n",
        "args.optim = \"AdamW\"\n",
        "\n",
        "# ====== Train, Validate, Test ====== #\n",
        "args.epoch = 10\n",
        "args.clip = 1 # Not in the paper!\n",
        "args.batch_size = 128"
      ],
      "metadata": {
        "id": "9cjYQcxyLwiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "1kK4aNatK3P7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Embedding\n",
        "* $PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}})$\n",
        "* $PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})$"
      ],
      "metadata": {
        "id": "lZrXybFhTlD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(max_len, hidden_dim, device):\n",
        "    pos = torch.arange(0, max_len).unsqueeze(1).to(device) # [[0], [1], [2], ..., [max_len-1]]\n",
        "    dim = torch.arange(0, hidden_dim, 2).to(device) # [0, 2, 4, 6, ..., hidden_dim-2]\n",
        "\n",
        "    # 각 차원의 주기를 다르게 하기 위한 계산\n",
        "    angle_rates = 1 / torch.pow(10000, (dim.float() / hidden_dim))\n",
        "\n",
        "    # sin과 cos을 계산하여 matrix에 넣음\n",
        "    pos_encoding = torch.zeros((max_len, hidden_dim)).to(device)\n",
        "    pos_encoding[:, 0::2] = torch.sin(pos * angle_rates)  # 짝수 인덱스는 sin\n",
        "    pos_encoding[:, 1::2] = torch.cos(pos * angle_rates)  # 홀수 인덱스는 cos\n",
        "\n",
        "    return pos_encoding.unsqueeze(0)  # 배치 차원을 추가하여 반환"
      ],
      "metadata": {
        "id": "YHWjt0sETm1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi Head Attention\n",
        "* hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
        "* n_heads: 헤드 개수\n",
        "* dropout_ratio: 드롭아웃 비율"
      ],
      "metadata": {
        "id": "b13Zq37cRtq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        assert hidden_dim % n_heads == 0 # hidden_dim은 n_heads* d_k 값과 동일함\n",
        "\n",
        "        self.hidden_dim = hidden_dim # 임베딩 차원\n",
        "        self.n_heads = n_heads # head의 개수\n",
        "        self.head_dim = hidden_dim // n_heads # hidden_dim은 n_heads* head_dim 값과 동일\n",
        "\n",
        "        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
        "        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
        "        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
        "\n",
        "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # query: [batch_size, query_len, hidden_dim]\n",
        "        # key: [batch_size, key_len, hidden_dim]\n",
        "        # value: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        # Q: [batch_size, query_len, hidden_dim]\n",
        "        # K: [batch_size, key_len, hidden_dim]\n",
        "        # V: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "        # hidden_dim → n_heads X head_dim 형태로 변형\n",
        "        # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Q: [batch_size, n_heads, query_len, head_dim]\n",
        "        # K: [batch_size, n_heads, key_len, head_dim]\n",
        "        # V: [batch_size, n_heads, value_len, head_dim]\n",
        "\n",
        "        # Attention Energy 계산\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "        # energy: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 마스크(mask)를 사용하는 경우\n",
        "        if mask is not None:\n",
        "            # 마스크(mask) 값이 0인 부분을 -1e10으로 채우기\n",
        "            energy = energy.masked_fill(mask==0, -1e10)\n",
        "\n",
        "        # 어텐션(attention) 스코어 계산: 각 단어에 대한 확률 값\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "        # attention: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 여기에서 Scaled Dot-Product Attention을 계산\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "        # x: [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # x: [batch_size, query_len, n_heads, head_dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hidden_dim)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        return x, attention"
      ],
      "metadata": {
        "id": "Zs0tVeCKtzTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feed-forward\n",
        "* same input-output dimension size\n",
        "* pf_dim: Feed-forward layer 내부의 임베딩 차원 (x2)"
      ],
      "metadata": {
        "id": "XvqTueIhR_IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "\n",
        "        # x: [batch_size, seq_len, pf_dim]\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "8OfBcZ4lK1oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder Layer\n",
        "* 하나의 인코더 레이어\n",
        "* input-output 차원 동일\n",
        "* '\\<pad>' 토큰 mask = 0"
      ],
      "metadata": {
        "id": "_vAD41-zSWa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # position-wise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src"
      ],
      "metadata": {
        "id": "HMtGBJu5K4U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder (Encoder Layer x enc_layers)\n",
        "* max_length: 문장 내 최대 단어 개수"
      ],
      "metadata": {
        "id": "Lm9cuiacSnTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.pos_embedding = positional_encoding(max_length, hidden_dim, device)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = self.pos_embedding[:, :src_len, :].to(self.device)\n",
        "\n",
        "        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 사용\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + pos)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        return src"
      ],
      "metadata": {
        "id": "YvOliABSK66S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder Layer\n",
        "* input-output 차원 동일\n",
        "* masked self-attention\n",
        "* cross attention"
      ],
      "metadata": {
        "id": "JVSCPNSSSygt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # encoder attention\n",
        "        # 디코더의 쿼리(Query)를 이용해 인코더를 어텐션(attention)\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return trg, attention"
      ],
      "metadata": {
        "id": "mw_h6RUOK6wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder (Decoder Layer x dec_layers)\n",
        "* Seq2Seq과는 마찬가지로 inference 시기에서는 디코더를 반복적으로 넣을 필요가 있음\n",
        "    * training 시기에서는 한 번에 출력 문장을 구해 학습할 수 있음"
      ],
      "metadata": {
        "id": "4cmSQdfmTA1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
        "        self.pos_embedding = positional_encoding(max_length, hidden_dim, device)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = self.pos_embedding[:, :trg_len, :].to(self.device)\n",
        "\n",
        "        # pos: [batch_size, trg_len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + pos)\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # 소스 마스크와 타겟 마스크 모두 사용\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "B3Vmed1kK_4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "wQoOwjhITRkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    # 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        \"\"\"\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 1 0\n",
        "        1 1 1 1 1\n",
        "        \"\"\"\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "\n",
        "        # trg_sub_mask: [trg_len, trg_len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "OW11ZTzlLBRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "9sHQyBxeLvBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Preparation"
      ],
      "metadata": {
        "id": "b5QqXxrKaqQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU Setting"
      ],
      "metadata": {
        "id": "V2XAGLZTP6be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "K0cWEkYfP8IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Initialization"
      ],
      "metadata": {
        "id": "51e1wXeMTXLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
        "enc = Encoder(args.input_dim, args.hidden_dim, args.enc_layers, args.enc_heads, args.enc_pf_dim, args.enc_dropout, device, args.max_len)\n",
        "dec = Decoder(args.output_dim, args.hidden_dim, args.dec_layers, args.dec_heads, args.dec_pf_dim, args.dec_dropout, device, args.max_len)\n",
        "\n",
        "# Transformer 객체 선언\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "\n",
        "# 모델 출력\n",
        "print(f\"Transformer model created with {args.enc_layers} encoder layers and {args.dec_layers} decoder layers.\")"
      ],
      "metadata": {
        "id": "TzArfEfhO8rx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight Initialization"
      ],
      "metadata": {
        "id": "9avynpe7ZCyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "metadata": {
        "id": "6oHbs6UwZFdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Scheduler"
      ],
      "metadata": {
        "id": "W8Tu6TJ6aQou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 학습률 스케줄러 정의\n",
        "class NoamScheduler(optim.lr_scheduler._LRScheduler):\n",
        "    def __init__(self, optimizer, hidden_dim, warmup_steps, last_epoch=-1):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.warmup_steps = warmup_steps\n",
        "        super(NoamScheduler, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        step_num = max(1, self._step_count)  # step이 0일 경우를 방지\n",
        "        scale = (self.hidden_dim ** -0.5) * min(step_num ** -0.5, step_num * (self.warmup_steps ** -1.5))\n",
        "        return [base_lr * scale for base_lr in self.base_lrs]\n",
        "\n",
        "# 모델의 옵티마이저 선택\n",
        "if args.optim == 'SGD':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "elif args.optim == 'RMSprop':\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "elif args.optim == 'Adam':\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "elif args.optim == 'AdamW':\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=args.lr, betas=(0.9, 0.98), eps=1e-9)\n",
        "else:\n",
        "    raise ValueError(f\"Invalid optimizer choice: {args.optim}\")\n",
        "\n",
        "# 학습률 스케줄러 정의\n",
        "scheduler = NoamScheduler(\n",
        "    optimizer=optimizer,               # 생성한 옵티마이저를 스케줄러에 전달\n",
        "    hidden_dim=args.hidden_dim,        # args에서 hidden_dim 가져오기\n",
        "    warmup_steps=args.warmup_steps     # args에서 warmup_steps 가져오기\n",
        ")"
      ],
      "metadata": {
        "id": "2JExR7dOaS75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Train, Evaluation Function"
      ],
      "metadata": {
        "id": "tvw19pWaatjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "Ue4XKNMfa7Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습(train) 함수\n",
        "def train(model, train_loader, args):\n",
        "\n",
        "    # 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "    if args.optim == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'AdamW':\n",
        "        optimizer =  torch.optim.AdamW(model.parameters(), lr=args.lr, betas=(0.9, 0.98), eps=1e-9)\n",
        "    else:\n",
        "        raise ValueError('In-valid optimizer choice')\n",
        "\n",
        "    model.train() # 학습 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # 전체 학습 데이터를 확인하며\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        src, trg = data\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 출력 단어의 마지막 인덱스(<eos>)는 제외\n",
        "        # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        # output: [배치 크기, trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기, trg_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        # 출력 단어의 인덱스 0(<sos>)은 제외\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "        # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(train_loader)"
      ],
      "metadata": {
        "id": "ym8ScLRfavzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "tbt6K8Gbbd4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, valid_loader):\n",
        "\n",
        "    # 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "    model.eval() # 평가 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "\n",
        "    # 전체 평가 데이터를 확인하며\n",
        "    for i, data in enumerate(valid_loader, 0):\n",
        "\n",
        "        src, trg = data\n",
        "\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        # 출력 단어의 마지막 인덱스(<eos>)는 제외\n",
        "        # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        # output: [배치 크기, trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기, trg_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        # 출력 단어의 인덱스 0(<sos>)은 제외\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "        # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(valid_loader)"
      ],
      "metadata": {
        "id": "EAk7t_SAbgLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "eqsGL8mWc3ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Validate"
      ],
      "metadata": {
        "id": "SQUCPwwQdL-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(args.epoch):\n",
        "    start_time = time.time() # 시작 시간 기록\n",
        "\n",
        "    train_loss = train(model, train_loader, args)\n",
        "    valid_loss = evaluate(model, valid_loader)\n",
        "\n",
        "    end_time = time.time() # 종료 시간 기록\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'transformer_korean_to_english.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
      ],
      "metadata": {
        "id": "-MspyQbHdOll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}