{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Module Import & Data Preparation"],"metadata":{"id":"f29WtLFlKzdD"}},{"cell_type":"markdown","source":["### Important Installations"],"metadata":{"id":"ofN-FJdWqw-d"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8tWzsbj2fmuk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de41841f-7d6f-4a15-9b74-306e398a8a92","executionInfo":{"status":"ok","timestamp":1727776887355,"user_tz":-540,"elapsed":95039,"user":{"displayName":"배고프다","userId":"10599614557067348512"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.12.0\n","  Downloading torchtext-0.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (8.0 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.12.0) (4.66.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.12.0) (2.32.3)\n","Collecting torch==1.11.0 (from torchtext==0.12.0)\n","  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.12.0) (1.26.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0->torchtext==0.12.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.12.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.12.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.12.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.12.0) (2024.8.30)\n","Downloading torchtext-0.12.0-cp310-cp310-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.4.1+cu121\n","    Uninstalling torch-2.4.1+cu121:\n","      Successfully uninstalled torch-2.4.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 1.11.0 which is incompatible.\n","torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.11.0 torchtext-0.12.0\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n","Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.0 konlpy-0.6.0\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"]}],"source":["!pip install torchtext==0.12.0\n","!pip install konlpy\n","!pip install openpyxl"]},{"cell_type":"code","source":["import torch\n","\n","print(\"Torch version:{}\".format(torch.__version__))\n","print(\"cuda version: {}\".format(torch.version.cuda))\n","print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qBJFkhVQ_Kj","executionInfo":{"status":"ok","timestamp":1727776888235,"user_tz":-540,"elapsed":882,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"outputId":"b2c92c4e-4da6-4621-f74f-2631bd3fc46a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch version:1.11.0+cu102\n","cuda version: 10.2\n","cudnn version:7605\n"]}]},{"cell_type":"markdown","source":["### Mount Google Drive"],"metadata":{"id":"3lR6B-6Zrxu2"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5STNCN07r7Iw","executionInfo":{"status":"ok","timestamp":1727776907484,"user_tz":-540,"elapsed":19251,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"outputId":"d7187537-f926-4771-81c4-434d5cf98fa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/24Fall_NLP')\n","# os.chdir('/content/drive/MyDrive/YAI/24Fall_NLP')"],"metadata":{"id":"N9hq8CQWsCQk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Import Mandatory Modules"],"metadata":{"id":"z4a-xfaatw3s"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import torchtext.transforms as transforms\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.data import Dataset, DataLoader\n","from konlpy.tag import Okt\n","from torchtext.datasets import Multi30k\n","\n","import spacy\n","import numpy as np\n","\n","import random\n","import math\n","import time"],"metadata":{"id":"AJYHGA942gbH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Preprocessing"],"metadata":{"id":"HVMyjN-Xqy8S"}},{"cell_type":"code","source":["from glob import glob\n","\n","data = glob('./한영번역_sample/*.xlsx')"],"metadata":{"id":"F3wFGQnhqp_5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = './한영번역_sample/'"],"metadata":{"id":"O4dxHn6X7CC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J2qAHLEEt_I-","executionInfo":{"status":"ok","timestamp":1727776929457,"user_tz":-540,"elapsed":3,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"outputId":"23e9b43e-ef71-438f-b54e-d83a200dfca1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['./한영번역_sample/2_대화체_190920.xlsx',\n"," './한영번역_sample/4_문어체_한국문화_190920.xlsx',\n"," './한영번역_sample/3_문어체_뉴스_190920.xlsx',\n"," './한영번역_sample/6_문어체_지자체웹사이트_190920.xlsx',\n"," './한영번역_sample/5_문어체_조례_190920.xlsx']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["file_list = [os.path.basename(file) for file in data]\n","\n","df = pd.DataFrame(columns=['kr', 'en'])\n","\n","for datum in data:\n","    temp = pd.read_excel(datum)\n","    exs_columns_en = [col for col in temp.columns if col in ['영어검수', '검수', 'Review', 'REVIEW']]\n","    exs_columns_kr = [col for col in temp.columns if col in ['원문','한국어']]\n","    if exs_columns_en:\n","        temp = temp.rename(columns={col:'en' for col in exs_columns_en})\n","    if exs_columns_kr:\n","        temp = temp.rename(columns={col:'kr' for col in exs_columns_kr})\n","\n","    df = pd.concat([df, temp[['kr', 'en']]])"],"metadata":{"collapsed":true,"id":"Wrn9mcvpufIl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.shape)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"QCcRFbpf1_sA","executionInfo":{"status":"ok","timestamp":1727776947040,"user_tz":-540,"elapsed":4,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"outputId":"6ed182f7-716c-4d62-855d-f6fe0718e1d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(56263, 2)\n"]},{"output_type":"execute_result","data":{"text/plain":["                                             kr  \\\n","0    이번 시험 혹시 범위가 어떻게 되는지 아세요? 제가 지난주 수업을 못가서요.   \n","1               네. 이번 시험은 100페이지부터 250페이지까지입니다.   \n","2             그렇군요. 감사합니다. 추가로 안내 받으신 사항 있으실까요?   \n","3  네. 시험 범위 외에 교수님께서 지난번에 주신 발표자료도 참고하라고 하셨습니다.   \n","4       역대 시험 난이도 분석중인데, 이번 시험 난이도는 어떻게 될것같습니까?   \n","\n","                                                  en  \n","0  Do you know which part our test is going to co...  \n","1   Yes. Our test will be from page 100 to page 250.  \n","2  I see, thanks! Did you have any additional inf...  \n","3  Yes. The professor also told us to look at the...  \n","4  I'm currently analyzing the level of difficult...  "],"text/html":["\n","  <div id=\"df-078da8c2-4cc8-4d27-91d2-99cff3812ab0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>kr</th>\n","      <th>en</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>이번 시험 혹시 범위가 어떻게 되는지 아세요? 제가 지난주 수업을 못가서요.</td>\n","      <td>Do you know which part our test is going to co...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>네. 이번 시험은 100페이지부터 250페이지까지입니다.</td>\n","      <td>Yes. Our test will be from page 100 to page 250.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>그렇군요. 감사합니다. 추가로 안내 받으신 사항 있으실까요?</td>\n","      <td>I see, thanks! Did you have any additional inf...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>네. 시험 범위 외에 교수님께서 지난번에 주신 발표자료도 참고하라고 하셨습니다.</td>\n","      <td>Yes. The professor also told us to look at the...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>역대 시험 난이도 분석중인데, 이번 시험 난이도는 어떻게 될것같습니까?</td>\n","      <td>I'm currently analyzing the level of difficult...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-078da8c2-4cc8-4d27-91d2-99cff3812ab0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-078da8c2-4cc8-4d27-91d2-99cff3812ab0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-078da8c2-4cc8-4d27-91d2-99cff3812ab0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-673fc912-8c6f-4ab2-8b0b-70b75c9ce045\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-673fc912-8c6f-4ab2-8b0b-70b75c9ce045')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-673fc912-8c6f-4ab2-8b0b-70b75c9ce045 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 56263,\n  \"fields\": [\n    {\n      \"column\": \"kr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56261,\n        \"samples\": [\n          \"\\uc758\\ud68c \\uc758\\uc7a5(\\uc774\\ud558 \\u201c\\uc758\\uc7a5\\u201d\\uc774\\ub77c \\ud55c\\ub2e4)\\uc740 \\ud1a0\\ub860\\ud68c \\ub4f1\\uc744 \\uacf5\\uc815\\ud558\\uace0 \\ud6a8\\uc728\\uc801\\uc73c\\ub85c \\uc6b4\\uc601\\ud568\\uc73c\\ub85c\\uc368 \\uad6c\\ubbfc\\uc758 \\uc758\\uacac\\uc744 \\uc801\\uadf9\\uc801\\uc73c\\ub85c \\uc218\\ub834\\ud558\\uc5ec\\uc57c \\ud55c\\ub2e4.\",\n          \"\\ubb38\\ub798\\ub3d9 \\ucabd\\ubc29\\ucd0c\\uc5d0 \\uc0b4\\uace0 \\uc788\\ub294 \\ud55c \\uc8fc\\ubbfc\\uc740 \\u201c\\ube44\\uac00 \\uc624\\uba74 \\ube44\\ub97c \\ub9de\\uc744 \\uc218\\ubc16\\uc5d0 \\uc5c6\\ub294 \\uac8c \\ucabd\\ubc29\\ucd0c \\uc0dd\\ud65c \\uc544\\ub2c8\\uaca0\\ub290\\ub0d0\\u201d\\uba70 \\u201c\\ube44\\uac00 \\uc9d1\\uc5d0 \\ub4e4\\uc774\\uce58\\uc9c0 \\uc54a\\ub3c4\\ub85d \\uc6b4\\uc5d0 \\ub9e1\\uae30\\ub294 \\uc218\\ubc16\\uc5d0 \\uc5c6\\ub2e4\\u201d\\uace0 \\ub9d0\\ud588\\ub2e4.\",\n          \"\\ubd80\\uc0b0\\uc5d0\\uc11c \\ubb34\\uc0c1\\uae09\\uc2dd\\uc740 \\uc9c0\\ub09c 2014\\ub144 3\\uc6d4 \\uacf5\\ub9bd \\ucd08\\ub4f1\\ud559\\uad50 \\uc804\\uba74 \\uc2e4\\uc2dc\\ub97c \\uc2dc\\uc791\\uc73c\\ub85c 2017\\ub144 3\\uc6d4\\ubaa8\\ub4e0 \\uc911\\ud559\\uad50\\ub85c \\ud655\\ub300\\ub410\\uc73c\\uba70, \\uc62c\\ud574\\ub294 \\uad6d\\u00b7\\uc0ac\\ub9bd \\ucd08\\ub4f1\\ud559\\uad50\\uae4c\\uc9c0 \\ud3ec\\ud568\\ud558\\uac8c \\ub410\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"en\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56219,\n        \"samples\": [\n          \"Administrative fines shall be imposed and collected by the head of the Gu pursuant to Articles 39, 40 and 44 of the Act.\",\n          \"Other matters necessary for promoting and supporting autonomous decentralization.\",\n          \"Identification cards shall contain the member certificate number, personal information, etc. and shall be accompanied by a photo, and the standards, rules, and entries shall be as specified in the attached Table.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### Dataset Preparation"],"metadata":{"id":"hqi32Xzu6C69"}},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","df_shuffled = df.sample(frac=1).reset_index(drop=True) # 전체 문장들을 무작위로 섞은 뒤 인덱스를 리셋해준다\n","df = df_shuffled[:30000] # 그 중 30,000개 문장만 가져와 사용\n","\n","for i, (train_idx, val_idx) in enumerate(kf.split(df['kr'])):\n","    train = df.iloc[train_idx]\n","    val = df.iloc[val_idx]\n","\n","print('train_size: ', len(train))\n","print('val_size: ', len(val))\n","\n","train.to_csv(os.path.join(data_path, 'train.csv'), index=False)\n","val.to_csv(os.path.join(data_path, 'val.csv'), index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOm1mBLu6NzM","executionInfo":{"status":"ok","timestamp":1727776949823,"user_tz":-540,"elapsed":2785,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"outputId":"0f70894b-39ed-45b4-b14a-09c8d3045a3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_size:  24000\n","val_size:  6000\n"]}]},{"cell_type":"code","source":["# 어휘 생성\n","def yield_tokens(data_iter, tokenizer):\n","    for text in data_iter:\n","        yield tokenizer(text)\n","\n","# 한국어와 영어 토크나이저 정의\n","tokenizer_kr = Okt()\n","tokenizer_en = spacy.load('en_core_web_sm')\n","\n","def tokenize_kor(text):\n","    return tokenizer_kr.morphs(text)\n","\n","def tokenize_en(text):\n","    return [token.text for token in tokenizer_en(text)]"],"metadata":{"id":"GwliQTb1I8c9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Sample Sentence Check"],"metadata":{"id":"DhXHQVmr2FeQ"}},{"cell_type":"code","source":["# 데이터셋에서 샘플 문장 확인\n","sample_kr_sentence = train_df['kr'].iloc[0]  # 첫 번째 샘플 문장 (한국어)\n","sample_en_sentence = train_df['en'].iloc[0]  # 첫 번째 샘플 문장 (영어)\n","\n","# 토큰화된 결과 출력\n","print(\"Korean Sentence:\", sample_kr_sentence)\n","print(\"Tokenized Korean:\", list(yield_tokens([sample_kr_sentence], tokenize_kor)))\n","\n","print(\"English Sentence:\", sample_en_sentence)\n","print(\"Tokenized English:\", list(yield_tokens([sample_en_sentence], tokenize_en)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkQhJ6XMolgM","executionInfo":{"status":"ok","timestamp":1727777299790,"user_tz":-540,"elapsed":3,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"outputId":"5ab015f7-83cf-4abc-829a-abf81a49598d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Korean Sentence: 조금 더 일찍 올 걸 그랬나. ATM 앞에 사람이 너무 많아. \n","Tokenized Korean: [['조금', '더', '일찍', '올', '걸', '그랬나', '.', 'ATM', '앞', '에', '사람', '이', '너무', '많아', '.']]\n","English Sentence: We should have come earlier. There are so many people in front of the ATM.\n","Tokenized English: [['We', 'should', 'have', 'come', 'earlier', '.', 'There', 'are', 'so', 'many', 'people', 'in', 'front', 'of', 'the', 'ATM', '.']]\n"]}]},{"cell_type":"code","source":["train_df = pd.read_csv(f'{data_path}train.csv')\n","valid_df = pd.read_csv(f'{data_path}val.csv')\n","\n","# 어휘 구축\n","SRC_vocab = build_vocab_from_iterator(yield_tokens(train_df['kr'], tokenize_kor), min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n","SRC_vocab.set_default_index(SRC_vocab['<unk>'])\n","\n","TRG_vocab = build_vocab_from_iterator(yield_tokens(train_df['en'], tokenize_en), min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n","TRG_vocab.set_default_index(TRG_vocab['<unk>'])\n","\n","print(f\"len(SRC_vocab): {len(SRC_vocab)}\")\n","print(f\"len(TRG_vocab): {len(TRG_vocab)}\")\n","\n","# Transforms 정의\n","SRC_transform = transforms.Sequential(\n","    transforms.VocabTransform(SRC_vocab),\n","    transforms.AddToken(token=SRC_vocab['<sos>'], begin=True),\n","    transforms.AddToken(token=SRC_vocab['<eos>'], begin=False)\n",")\n","\n","TRG_transform = transforms.Sequential(\n","    transforms.VocabTransform(TRG_vocab),\n","    transforms.AddToken(token=TRG_vocab['<sos>'], begin=True),\n","    transforms.AddToken(token=TRG_vocab['<eos>'], begin=False)\n",")"],"metadata":{"id":"zeb1H9oIDSj-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CSV 파일을 처리하여 텐서로 변환하는 Dataset 클래스\n","class TranslationDataset(Dataset):\n","    def __init__(self, path, src_transform=None, trg_transform=None):\n","        self.data = pd.read_csv(path)\n","        self.src_transform = src_transform\n","        self.trg_transform = trg_transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        src_text = self.data.iloc[idx]['kr']\n","        trg_text = self.data.iloc[idx]['en']\n","\n","        # 토큰화 적용\n","        src_tokenized = tokenize_kor(src_text)\n","        trg_tokenized = tokenize_en(trg_text)\n","\n","        # 변환 적용 (리스트로 감싸서 transform 적용)\n","        if self.src_transform:\n","            src_text = self.src_transform([src_tokenized])  # 리스트로 감싸서 transform 적용\n","        if self.trg_transform:\n","            trg_text = self.trg_transform([trg_tokenized])  # 리스트로 감싸서 transform 적용\n","\n","        return torch.tensor(src_text[0]), torch.tensor(trg_text[0])  # 텐서로 변환"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WifGkw2uzZBS","executionInfo":{"status":"ok","timestamp":1727777299789,"user_tz":-540,"elapsed":346902,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"outputId":"411160b7-19dd-4717-baef-945bb05589df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["len(SRC_vocab): 18393\n","len(TRG_vocab): 15056\n"]}]},{"cell_type":"code","source":["def collate_fn(batch):\n","    src_batch, trg_batch = [], []\n","    for src_sample, trg_sample in batch:\n","        src_batch.append(src_sample)\n","        trg_batch.append(trg_sample)\n","\n","    # 텐서로 변환하고 패딩 처리\n","    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=SRC_vocab['<pad>'], batch_first=True)\n","    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=TRG_vocab['<pad>'], batch_first=True)\n","\n","    return src_batch, trg_batch"],"metadata":{"id":"0epjeOscJETr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DataLoader 설정\n","BATCH_SIZE = 128\n","\n","# Dataset 생성\n","train_data = TranslationDataset(train_csv, src_transform=SRC_transform, trg_transform=TRG_transform)\n","valid_data = TranslationDataset(valid_csv, src_transform=SRC_transform, trg_transform=TRG_transform)\n","\n","# DataLoader 생성\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n","valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n","\n","# Batch shape 확인\n","for src, trg in train_loader:\n","    print(f\"Source batch shape: {src.shape}\")\n","    print(f\"Target batch shape: {trg.shape}\")\n","    break"],"metadata":{"id":"B-7Nau8TJGB1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define Dataset, DataLoader"],"metadata":{"id":"xrym5a1oQVG9"}},{"cell_type":"code","source":["# Dataset 생성\n","train_data = TranslationDataset(train_csv, src_transform=SRC_transform, trg_transform=TRG_transform)\n","valid_data = TranslationDataset(valid_csv, src_transform=SRC_transform, trg_transform=TRG_transform)\n","\n","# DataLoader 설정\n","BATCH_SIZE = 128\n","\n","def collate_fn(batch):\n","    src_batch, trg_batch = [], []\n","    for src_sample, trg_sample in batch:\n","        src_batch.append(src_sample)\n","        trg_batch.append(trg_sample)\n","\n","    # 텐서로 변환하고 패딩 처리\n","    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=SRC_vocab['<pad>'], batch_first=True)\n","    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=TRG_vocab['<pad>'], batch_first=True)\n","\n","    return src_batch, trg_batch\n","\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n","valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n","\n","# DataLoader에서 배치를 받아오는 예시\n","for src, trg in train_loader:\n","    print(f\"Source batch shape: {src.shape}\")\n","    print(f\"Target batch shape: {trg.shape}\")\n","    break"],"metadata":{"id":"otD7a_7XDOkZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727777301655,"user_tz":-540,"elapsed":1867,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"outputId":"e04d493e-7137-4c7e-cfe6-b0ec730ee397"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Source batch shape: torch.Size([128, 74])\n","Target batch shape: torch.Size([128, 84])\n"]}]},{"cell_type":"markdown","source":["# Hyper Parameters"],"metadata":{"id":"C4ZG5HqhQHCR"}},{"cell_type":"code","source":["import argparse\n","\n","parser = argparse.ArgumentParser()\n","args = parser.parse_args(\"\")\n","\n","# ====== Random Seed Initialization ====== #\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","# ====== Padding Index Setting ====== #\n","# indices of <pad> token\n","SRC_PAD_IDX = SRC_vocab['<pad>']\n","TRG_PAD_IDX = TRG_vocab['<pad>']\n","\n","# ====== Model ====== #\n","args.input_dim = len(SRC_vocab)\n","args.output_dim = len(TRG_vocab)\n","\n","args.hidden_dim = 256 # 512 in the original paper\n","\n","args.max_len = 200 # >= sentence max length\n","\n","args.enc_layers = 3 # 6 in the original paper\n","args.dec_layers = 3\n","\n","args.enc_heads = 8\n","args.dec_heads = 8\n","\n","args.enc_pf_dim = 1024 # 2048 in the original paper\n","args.dec_pf_dim = 1024\n","\n","args.enc_dropout = 0.1\n","args.dec_dropout = 0.1\n","\n","# ====== Optimization ====== #\n","args.lr = 0.0005\n","args.warmup_steps = 4000\n","\n","args.optim = \"AdamW\"\n","\n","# ====== Train, Validate, Test ====== #\n","args.epoch = 10\n","args.clip = 1 # Not in the paper!\n","args.batch_size = 128"],"metadata":{"id":"9cjYQcxyLwiK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Architecture"],"metadata":{"id":"1kK4aNatK3P7"}},{"cell_type":"markdown","source":["### Positional Embedding\n","* $PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}})$\n","* $PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})$"],"metadata":{"id":"lZrXybFhTlD9"}},{"cell_type":"code","source":["def positional_encoding(max_len, hidden_dim, device):\n","    pos = torch.arange(0, max_len).unsqueeze(1).to(device) # [[0], [1], [2], ..., [max_len-1]]\n","    dim = torch.arange(0, hidden_dim, 2).to(device) # [0, 2, 4, 6, ..., hidden_dim-2]\n","\n","    # 각 차원의 주기를 다르게 하기 위한 계산\n","    angle_rates = 1 / torch.pow(10000, (dim.float() / hidden_dim))\n","\n","    # sin과 cos을 계산하여 matrix에 넣음\n","    pos_encoding = torch.zeros((max_len, hidden_dim)).to(device)\n","    pos_encoding[:, 0::2] = torch.sin(pos * angle_rates)  # 짝수 인덱스는 sin\n","    pos_encoding[:, 1::2] = torch.cos(pos * angle_rates)  # 홀수 인덱스는 cos\n","\n","    return pos_encoding.unsqueeze(0)  # 배치 차원을 추가하여 반환"],"metadata":{"id":"YHWjt0sETm1-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Multi Head Attention\n","* hidden_dim: 하나의 단어에 대한 임베딩 차원\n","* n_heads: 헤드 개수\n","* dropout_ratio: 드롭아웃 비율"],"metadata":{"id":"b13Zq37cRtq9"}},{"cell_type":"code","source":["class MultiHeadAttentionLayer(nn.Module):\n","    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n","        super().__init__()\n","\n","        assert hidden_dim % n_heads == 0 # hidden_dim은 n_heads* d_k 값과 동일함\n","\n","        self.hidden_dim = hidden_dim # 임베딩 차원\n","        self.n_heads = n_heads # head의 개수\n","        self.head_dim = hidden_dim // n_heads # hidden_dim은 n_heads* head_dim 값과 동일\n","\n","        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n","        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n","        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n","\n","        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n","\n","        self.dropout = nn.Dropout(dropout_ratio)\n","\n","        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n","\n","    def forward(self, query, key, value, mask = None):\n","\n","        batch_size = query.shape[0]\n","\n","        # query: [batch_size, query_len, hidden_dim]\n","        # key: [batch_size, key_len, hidden_dim]\n","        # value: [batch_size, value_len, hidden_dim]\n","\n","        Q = self.fc_q(query)\n","        K = self.fc_k(key)\n","        V = self.fc_v(value)\n","\n","        # Q: [batch_size, query_len, hidden_dim]\n","        # K: [batch_size, key_len, hidden_dim]\n","        # V: [batch_size, value_len, hidden_dim]\n","\n","        # hidden_dim → n_heads X head_dim 형태로 변형\n","        # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n","        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","\n","        # Q: [batch_size, n_heads, query_len, head_dim]\n","        # K: [batch_size, n_heads, key_len, head_dim]\n","        # V: [batch_size, n_heads, value_len, head_dim]\n","\n","        # Attention Energy 계산\n","        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n","\n","        # energy: [batch_size, n_heads, query_len, key_len]\n","\n","        # 마스크(mask)를 사용하는 경우\n","        if mask is not None:\n","            # 마스크(mask) 값이 0인 부분을 -1e10으로 채우기\n","            energy = energy.masked_fill(mask==0, -1e10)\n","\n","        # 어텐션(attention) 스코어 계산: 각 단어에 대한 확률 값\n","        attention = torch.softmax(energy, dim=-1)\n","\n","        # attention: [batch_size, n_heads, query_len, key_len]\n","\n","        # 여기에서 Scaled Dot-Product Attention을 계산\n","        x = torch.matmul(self.dropout(attention), V)\n","\n","        # x: [batch_size, n_heads, query_len, head_dim]\n","\n","        x = x.permute(0, 2, 1, 3).contiguous()\n","\n","        # x: [batch_size, query_len, n_heads, head_dim]\n","\n","        x = x.view(batch_size, -1, self.hidden_dim)\n","\n","        # x: [batch_size, query_len, hidden_dim]\n","\n","        x = self.fc_o(x)\n","\n","        # x: [batch_size, query_len, hidden_dim]\n","\n","        return x, attention"],"metadata":{"id":"Zs0tVeCKtzTk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Feed-forward\n","* same input-output dimension size\n","* pf_dim: Feed-forward layer 내부의 임베딩 차원 (x2)"],"metadata":{"id":"XvqTueIhR_IX"}},{"cell_type":"code","source":["class PositionwiseFeedforwardLayer(nn.Module):\n","    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n","        super().__init__()\n","\n","        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n","        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n","\n","        self.dropout = nn.Dropout(dropout_ratio)\n","\n","    def forward(self, x):\n","\n","        # x: [batch_size, seq_len, hidden_dim]\n","\n","        x = self.dropout(torch.relu(self.fc_1(x)))\n","\n","        # x: [batch_size, seq_len, pf_dim]\n","\n","        x = self.fc_2(x)\n","\n","        # x: [batch_size, seq_len, hidden_dim]\n","\n","        return x"],"metadata":{"id":"8OfBcZ4lK1oG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Encoder Layer\n","* 하나의 인코더 레이어\n","* input-output 차원 동일\n","* '\\<pad>' 토큰 mask = 0"],"metadata":{"id":"_vAD41-zSWa9"}},{"cell_type":"code","source":["class EncoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n","        super().__init__()\n","\n","        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n","        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n","        self.dropout = nn.Dropout(dropout_ratio)\n","\n","    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n","    def forward(self, src, src_mask):\n","\n","        # src: [batch_size, src_len, hidden_dim]\n","        # src_mask: [batch_size, src_len]\n","\n","        # self attention\n","        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n","        _src, _ = self.self_attention(src, src, src, src_mask)\n","\n","        # dropout, residual connection and layer norm\n","        src = self.self_attn_layer_norm(src + self.dropout(_src))\n","\n","        # src: [batch_size, src_len, hidden_dim]\n","\n","        # position-wise feedforward\n","        _src = self.positionwise_feedforward(src)\n","\n","        # dropout, residual and layer norm\n","        src = self.ff_layer_norm(src + self.dropout(_src))\n","\n","        # src: [batch_size, src_len, hidden_dim]\n","\n","        return src"],"metadata":{"id":"HMtGBJu5K4U2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Encoder (Encoder Layer x enc_layers)\n","* max_length: 문장 내 최대 단어 개수"],"metadata":{"id":"Lm9cuiacSnTh"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length):\n","        super().__init__()\n","\n","        self.device = device\n","\n","        self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n","        self.pos_embedding = positional_encoding(max_length, hidden_dim, device)\n","\n","        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n","\n","        self.dropout = nn.Dropout(dropout_ratio)\n","\n","        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n","\n","    def forward(self, src, src_mask):\n","\n","        # src: [batch_size, src_len]\n","        # src_mask: [batch_size, src_len]\n","\n","        batch_size = src.shape[0]\n","        src_len = src.shape[1]\n","\n","        pos = self.pos_embedding[:, :src_len, :].to(self.device)\n","\n","        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 사용\n","        src = self.dropout((self.tok_embedding(src) * self.scale) + pos)\n","\n","        for layer in self.layers:\n","            src = layer(src, src_mask)\n","\n","        return src"],"metadata":{"id":"YvOliABSK66S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decoder Layer\n","* input-output 차원 동일\n","* masked self-attention\n","* cross attention"],"metadata":{"id":"JVSCPNSSSygt"}},{"cell_type":"code","source":["class DecoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n","        super().__init__()\n","\n","        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n","        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n","        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n","        self.dropout = nn.Dropout(dropout_ratio)\n","\n","    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","\n","        # trg: [batch_size, trg_len, hidden_dim]\n","        # enc_src: [batch_size, src_len, hidden_dim]\n","        # trg_mask: [batch_size, trg_len]\n","        # src_mask: [batch_size, src_len]\n","\n","        # self attention\n","        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n","\n","        # dropout, residual connection and layer norm\n","        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n","\n","        # encoder attention\n","        # 디코더의 쿼리(Query)를 이용해 인코더를 어텐션(attention)\n","        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n","\n","        # dropout, residual connection and layer norm\n","        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n","\n","        # positionwise feedforward\n","        _trg = self.positionwise_feedforward(trg)\n","\n","        # dropout, residual and layer norm\n","        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n","\n","        # attention: [batch_size, n_heads, trg_len, src_len]\n","\n","        return trg, attention"],"metadata":{"id":"mw_h6RUOK6wO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decoder (Decoder Layer x dec_layers)\n","* Seq2Seq과는 마찬가지로 inference 시기에서는 디코더를 반복적으로 넣을 필요가 있음\n","    * training 시기에서는 한 번에 출력 문장을 구해 학습할 수 있음"],"metadata":{"id":"4cmSQdfmTA1t"}},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length):\n","        super().__init__()\n","\n","        self.device = device\n","\n","        self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n","        self.pos_embedding = positional_encoding(max_length, hidden_dim, device)\n","\n","        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n","\n","        self.fc_out = nn.Linear(hidden_dim, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout_ratio)\n","\n","        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n","\n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","\n","        # trg: [batch_size, trg_len]\n","        # enc_src: [batch_size, src_len, hidden_dim]\n","        # trg_mask: [batch_size, trg_len]\n","        # src_mask: [batch_size, src_len]\n","\n","        batch_size = trg.shape[0]\n","        trg_len = trg.shape[1]\n","\n","        pos = self.pos_embedding[:, :trg_len, :].to(self.device)\n","\n","        # pos: [batch_size, trg_len]\n","\n","        trg = self.dropout((self.tok_embedding(trg) * self.scale) + pos)\n","\n","        # trg: [batch_size, trg_len, hidden_dim]\n","\n","        for layer in self.layers:\n","            # 소스 마스크와 타겟 마스크 모두 사용\n","            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n","\n","        # attention: [batch_size, n_heads, trg_len, src_len]\n","\n","        output = self.fc_out(trg)\n","\n","        # output: [batch_size, trg_len, output_dim]\n","\n","        return output, attention"],"metadata":{"id":"B3Vmed1kK_4o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformer"],"metadata":{"id":"wQoOwjhITRkH"}},{"cell_type":"code","source":["class Transformer(nn.Module):\n","    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_pad_idx = src_pad_idx\n","        self.trg_pad_idx = trg_pad_idx\n","        self.device = device\n","\n","    # 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n","    def make_src_mask(self, src):\n","\n","        # src: [batch_size, src_len]\n","\n","        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n","\n","        # src_mask: [batch_size, 1, 1, src_len]\n","\n","        return src_mask\n","\n","    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n","    def make_trg_mask(self, trg):\n","\n","        # trg: [batch_size, trg_len]\n","\n","        \"\"\" (마스크 예시)\n","        1 0 0 0 0\n","        1 1 0 0 0\n","        1 1 1 0 0\n","        1 1 1 0 0\n","        1 1 1 0 0\n","        \"\"\"\n","        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n","\n","        # trg_pad_mask: [batch_size, 1, 1, trg_len]\n","\n","        trg_len = trg.shape[1]\n","\n","        \"\"\" (마스크 예시)\n","        1 0 0 0 0\n","        1 1 0 0 0\n","        1 1 1 0 0\n","        1 1 1 1 0\n","        1 1 1 1 1\n","        \"\"\"\n","        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n","\n","        # trg_sub_mask: [trg_len, trg_len]\n","\n","        trg_mask = trg_pad_mask & trg_sub_mask\n","\n","        # trg_mask: [batch_size, 1, trg_len, trg_len]\n","\n","        return trg_mask\n","\n","    def forward(self, src, trg):\n","\n","        # src: [batch_size, src_len]\n","        # trg: [batch_size, trg_len]\n","\n","        src_mask = self.make_src_mask(src)\n","        trg_mask = self.make_trg_mask(trg)\n","\n","        # src_mask: [batch_size, 1, 1, src_len]\n","        # trg_mask: [batch_size, 1, trg_len, trg_len]\n","\n","        enc_src = self.encoder(src, src_mask)\n","\n","        # enc_src: [batch_size, src_len, hidden_dim]\n","\n","        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n","\n","        # output: [batch_size, trg_len, output_dim]\n","        # attention: [batch_size, n_heads, trg_len, src_len]\n","\n","        return output, attention"],"metadata":{"id":"OW11ZTzlLBRN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"9sHQyBxeLvBb"}},{"cell_type":"markdown","source":["## Train Preparation"],"metadata":{"id":"b5QqXxrKaqQL"}},{"cell_type":"markdown","source":["### GPU Setting"],"metadata":{"id":"V2XAGLZTP6be"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"K0cWEkYfP8IE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Initialization"],"metadata":{"id":"51e1wXeMTXLr"}},{"cell_type":"code","source":["# 인코더(encoder)와 디코더(decoder) 객체 선언\n","enc = Encoder(args.input_dim, args.hidden_dim, args.enc_layers, args.enc_heads, args.enc_pf_dim, args.enc_dropout, device, args.max_len)\n","dec = Decoder(args.output_dim, args.hidden_dim, args.dec_layers, args.dec_heads, args.dec_pf_dim, args.dec_dropout, device, args.max_len)\n","\n","# Transformer 객체 선언\n","model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n","\n","# 모델 출력\n","print(f\"Transformer model created with {args.enc_layers} encoder layers and {args.dec_layers} decoder layers.\")"],"metadata":{"id":"TzArfEfhO8rx","executionInfo":{"status":"ok","timestamp":1727777306616,"user_tz":-540,"elapsed":4964,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"90bd28e2-c13c-41f5-a3a1-64f94ac8a857"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Transformer model created with 3 encoder layers and 3 decoder layers.\n"]}]},{"cell_type":"markdown","source":["### Weight Initialization"],"metadata":{"id":"9avynpe7ZCyK"}},{"cell_type":"code","source":["def initialize_weights(m):\n","    if hasattr(m, 'weight') and m.weight.dim() > 1:\n","        nn.init.xavier_uniform_(m.weight.data)\n","\n","model.apply(initialize_weights)"],"metadata":{"id":"6oHbs6UwZFdT","executionInfo":{"status":"ok","timestamp":1727777306616,"user_tz":-540,"elapsed":4,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cbd5e1eb-5835-4df6-d6c7-8b2106dde7ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Transformer(\n","  (encoder): Encoder(\n","    (tok_embedding): Embedding(18393, 256)\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (self_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n","          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n","          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (self_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n","          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n","          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (self_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n","          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n","          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (tok_embedding): Embedding(15056, 256)\n","    (layers): ModuleList(\n","      (0): DecoderLayer(\n","        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (self_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (encoder_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n","          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n","          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): DecoderLayer(\n","        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (self_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (encoder_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n","          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n","          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): DecoderLayer(\n","        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (self_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (encoder_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n","          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n","          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (fc_out): Linear(in_features=256, out_features=15056, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n",")"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["### Define Scheduler"],"metadata":{"id":"W8Tu6TJ6aQou"}},{"cell_type":"code","source":["\n","# 학습률 스케줄러 정의\n","class NoamScheduler(optim.lr_scheduler._LRScheduler):\n","    def __init__(self, optimizer, hidden_dim, warmup_steps, last_epoch=-1):\n","        self.hidden_dim = hidden_dim\n","        self.warmup_steps = warmup_steps\n","        super(NoamScheduler, self).__init__(optimizer, last_epoch)\n","\n","    def get_lr(self):\n","        step_num = max(1, self._step_count)  # step이 0일 경우를 방지\n","        scale = (self.hidden_dim ** -0.5) * min(step_num ** -0.5, step_num * (self.warmup_steps ** -1.5))\n","        return [base_lr * scale for base_lr in self.base_lrs]\n","\n","# 모델의 옵티마이저 선택\n","if args.optim == 'SGD':\n","    optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","elif args.optim == 'RMSprop':\n","    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","elif args.optim == 'Adam':\n","    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","elif args.optim == 'AdamW':\n","    optimizer = optim.AdamW(model.parameters(), lr=args.lr, betas=(0.9, 0.98), eps=1e-9)\n","else:\n","    raise ValueError(f\"Invalid optimizer choice: {args.optim}\")\n","\n","# 학습률 스케줄러 정의\n","scheduler = NoamScheduler(\n","    optimizer=optimizer,               # 생성한 옵티마이저를 스케줄러에 전달\n","    hidden_dim=args.hidden_dim,        # args에서 hidden_dim 가져오기\n","    warmup_steps=args.warmup_steps     # args에서 warmup_steps 가져오기\n",")"],"metadata":{"id":"2JExR7dOaS75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Train, Evaluation Function"],"metadata":{"id":"tvw19pWaatjb"}},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"Ue4XKNMfa7Ex"}},{"cell_type":"code","source":["# 모델 학습(train) 함수\n","def train(model, train_loader, args):\n","\n","    # 뒷 부분의 패딩(padding)에 대해서는 값 무시\n","    criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n","\n","    if args.optim == 'SGD':\n","        optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","    elif args.optim == 'RMSprop':\n","        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","    elif args.optim == 'Adam':\n","        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","    elif args.optim == 'AdamW':\n","        optimizer =  torch.optim.AdamW(model.parameters(), lr=args.lr, betas=(0.9, 0.98), eps=1e-9)\n","    else:\n","        raise ValueError('In-valid optimizer choice')\n","\n","    model.train() # 학습 모드\n","    epoch_loss = 0\n","\n","    # 전체 학습 데이터를 확인하며\n","    for i, data in enumerate(train_loader, 0):\n","\n","        src, trg = data\n","        src = src.to(device)\n","        trg = trg.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # 출력 단어의 마지막 인덱스(<eos>)는 제외\n","        # 입력을 할 때는 <sos>부터 시작하도록 처리\n","        output, _ = model(src, trg[:,:-1])\n","\n","        # output: [배치 크기, trg_len - 1, output_dim]\n","        # trg: [배치 크기, trg_len]\n","\n","        output_dim = output.shape[-1]\n","\n","        output = output.contiguous().view(-1, output_dim)\n","        # 출력 단어의 인덱스 0(<sos>)은 제외\n","        trg = trg[:,1:].contiguous().view(-1)\n","\n","        # output: [배치 크기 * trg_len - 1, output_dim]\n","        # trg: [배치 크기 * trg len - 1]\n","\n","        loss = criterion(output, trg)\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(train_loader)"],"metadata":{"id":"ym8ScLRfavzi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluate"],"metadata":{"id":"tbt6K8Gbbd4b"}},{"cell_type":"code","source":["def evaluate(model, valid_loader):\n","\n","    # 뒷 부분의 패딩(padding)에 대해서는 값 무시\n","    criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n","\n","    model.eval() # 평가 모드\n","    epoch_loss = 0\n","\n","\n","    # 전체 평가 데이터를 확인하며\n","    for i, data in enumerate(valid_loader, 0):\n","\n","        src, trg = data\n","\n","        src = src.to(device)\n","        trg = trg.to(device)\n","\n","        # 출력 단어의 마지막 인덱스(<eos>)는 제외\n","        # 입력을 할 때는 <sos>부터 시작하도록 처리\n","        output, _ = model(src, trg[:,:-1])\n","\n","        # output: [배치 크기, trg_len - 1, output_dim]\n","        # trg: [배치 크기, trg_len]\n","\n","        output_dim = output.shape[-1]\n","\n","        output = output.contiguous().view(-1, output_dim)\n","        # 출력 단어의 인덱스 0(<sos>)은 제외\n","        trg = trg[:,1:].contiguous().view(-1)\n","\n","        # output: [배치 크기 * trg_len - 1, output_dim]\n","        # trg: [배치 크기 * trg len - 1]\n","\n","        loss = criterion(output, trg)\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(valid_loader)"],"metadata":{"id":"EAk7t_SAbgLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"eqsGL8mWc3ha"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train & Validate"],"metadata":{"id":"SQUCPwwQdL-N"}},{"cell_type":"code","source":["best_valid_loss = float('inf')\n","\n","for epoch in range(args.epoch):\n","    start_time = time.time() # 시작 시간 기록\n","\n","    train_loss = train(model, train_loader, args)\n","    valid_loss = evaluate(model, valid_loader)\n","\n","    end_time = time.time() # 종료 시간 기록\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'transformer_korean_to_english.pt')\n","\n","    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n","    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"],"metadata":{"id":"-MspyQbHdOll","executionInfo":{"status":"ok","timestamp":1727782377776,"user_tz":-540,"elapsed":5071162,"user":{"displayName":"배고프다","userId":"10599614557067348512"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"70d1fcb2-514c-45fa-d217-6e5146e87168"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Time: 8m 25s\n","\tTrain Loss: 6.156 | Train PPL: 471.694\n","\tValidation Loss: 4.909 | Validation PPL: 135.534\n","Epoch: 02 | Time: 8m 27s\n","\tTrain Loss: 4.733 | Train PPL: 113.688\n","\tValidation Loss: 4.378 | Validation PPL: 79.675\n","Epoch: 03 | Time: 8m 26s\n","\tTrain Loss: 4.304 | Train PPL: 73.999\n","\tValidation Loss: 4.111 | Validation PPL: 60.996\n","Epoch: 04 | Time: 8m 24s\n","\tTrain Loss: 4.026 | Train PPL: 56.016\n","\tValidation Loss: 3.937 | Validation PPL: 51.271\n","Epoch: 05 | Time: 8m 25s\n","\tTrain Loss: 3.805 | Train PPL: 44.905\n","\tValidation Loss: 3.827 | Validation PPL: 45.945\n","Epoch: 06 | Time: 8m 29s\n","\tTrain Loss: 3.612 | Train PPL: 37.052\n","\tValidation Loss: 3.735 | Validation PPL: 41.876\n","Epoch: 07 | Time: 8m 26s\n","\tTrain Loss: 3.448 | Train PPL: 31.442\n","\tValidation Loss: 3.652 | Validation PPL: 38.535\n","Epoch: 08 | Time: 8m 30s\n","\tTrain Loss: 3.289 | Train PPL: 26.806\n","\tValidation Loss: 3.607 | Validation PPL: 36.864\n","Epoch: 09 | Time: 8m 22s\n","\tTrain Loss: 3.141 | Train PPL: 23.132\n","\tValidation Loss: 3.567 | Validation PPL: 35.395\n","Epoch: 10 | Time: 8m 25s\n","\tTrain Loss: 3.001 | Train PPL: 20.113\n","\tValidation Loss: 3.539 | Validation PPL: 34.430\n"]}]}]}